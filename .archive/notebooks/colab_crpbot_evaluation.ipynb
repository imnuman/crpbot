{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRPBot Model Evaluation\n",
    "\n",
    "**Models**: 3 LSTM (BTC, ETH, SOL) - 128/3/bidirectional, 50 features  \n",
    "**Goal**: Evaluate against promotion gates (â‰¥68% accuracy, â‰¤5% calibration error)  \n",
    "**Time**: ~5-10 minutes on GPU  \n",
    "**Files**: `/My Drive/crpbot/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ GPU not found! Runtime â†’ Change runtime type â†’ GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q loguru pandas pyarrow scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Mount Google Drive & Verify Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "drive_path = '/content/drive/MyDrive/crpbot'\n",
    "\n",
    "print(f\"\\nğŸ“‚ Checking: {drive_path}\")\n",
    "print(f\"Exists: {os.path.exists(drive_path)}\\n\")\n",
    "\n",
    "if os.path.exists(drive_path):\n",
    "    print(\"Contents:\")\n",
    "    !ls -lh /content/drive/MyDrive/crpbot/\n",
    "else:\n",
    "    print(\"âŒ ERROR: Folder not found!\")\n",
    "    print(\"Expected: /My Drive/crpbot/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Copy Files to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models/new data/features\n",
    "\n",
    "# Try multiple folder structures\n",
    "print(\"ğŸ“¦ Copying models...\")\n",
    "!cp /content/drive/MyDrive/crpbot/models/*.pt models/new/ 2>/dev/null || \\\n",
    " cp /content/drive/MyDrive/crpbot/*.pt models/new/ 2>/dev/null || \\\n",
    " echo \"âš ï¸ No .pt files found\"\n",
    "\n",
    "print(\"\\nğŸ“¦ Copying features...\")\n",
    "!cp /content/drive/MyDrive/crpbot/features/*.parquet data/features/ 2>/dev/null || \\\n",
    " cp /content/drive/MyDrive/crpbot/*.parquet data/features/ 2>/dev/null || \\\n",
    " echo \"âš ï¸ No .parquet files found\"\n",
    "\n",
    "# Verify\n",
    "import glob\n",
    "models = glob.glob('models/new/*.pt')\n",
    "features = glob.glob('data/features/*.parquet')\n",
    "\n",
    "print(f\"\\nâœ… Ready:\")\n",
    "print(f\"  Models: {len(models)}/3\")\n",
    "print(f\"  Features: {len(features)}/3\")\n",
    "\n",
    "if len(models) == 3 and len(features) == 3:\n",
    "    print(\"\\nğŸ‰ All files copied successfully!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Missing files. Check your Drive structure.\")\n",
    "    print(\"\\nModels:\")\n",
    "    !ls -lh models/new/\n",
    "    print(\"\\nFeatures:\")\n",
    "    !ls -lh data/features/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Code Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p apps/trainer/{models,train} libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apps/__init__.py\n",
    "# Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apps/trainer/__init__.py\n",
    "# Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apps/trainer/models/__init__.py\n",
    "# Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apps/trainer/train/__init__.py\n",
    "# Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apps/trainer/models/lstm.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 3, dropout: float = 0.2, bidirectional: bool = True):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0, bidirectional=bidirectional)\n",
    "        lstm_out_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.fc1 = nn.Linear(lstm_out_size, 64)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        x = torch.relu(self.fc1(out[:, -1, :]))\n",
    "        return self.sigmoid(self.fc2(self.dropout(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apps/trainer/data_pipeline.py\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "def load_features_from_parquet(symbol: str, features_dir: str = \"data/features\"):\n",
    "    patterns = [f\"features_{symbol}_1m_latest.parquet\", f\"features_{symbol}_1m_*_50feat.parquet\", f\"features_{symbol}_*.parquet\"]\n",
    "    for pattern in patterns:\n",
    "        files = list(Path(features_dir).glob(pattern))\n",
    "        if files:\n",
    "            path = sorted(files)[-1]\n",
    "            df = pd.read_parquet(path)\n",
    "            logger.info(f\"Loaded {path.name}: {len(df):,} rows, {len(df.columns)} cols\")\n",
    "            return df\n",
    "    raise FileNotFoundError(f\"No features for {symbol}\")\n",
    "\n",
    "def create_walk_forward_splits(df, train_ratio=0.7, val_ratio=0.15):\n",
    "    n = len(df)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = int(n * (train_ratio + val_ratio))\n",
    "    train_df = df.iloc[:train_end].copy()\n",
    "    val_df = df.iloc[train_end:val_end].copy()\n",
    "    test_df = df.iloc[val_end:].copy()\n",
    "    logger.info(f\"Splits: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apps/trainer/features.py\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    \"session_tokyo\", \"session_london\", \"session_ny\", \"day_of_week\", \"is_weekend\",\n",
    "    \"spread\", \"spread_pct\", \"atr\", \"spread_atr_ratio\",\n",
    "    \"volume_ma\", \"volume_ratio\", \"volume_trend\",\n",
    "    \"sma_7\", \"sma_14\", \"sma_21\", \"sma_50\", \"price_to_sma_7\", \"price_to_sma_14\", \"price_to_sma_21\", \"price_to_sma_50\",\n",
    "    \"rsi\", \"macd\", \"macd_signal\", \"macd_diff\", \"bb_upper\", \"bb_middle\", \"bb_lower\", \"bb_width\",\n",
    "    \"5m_open\", \"5m_high\", \"5m_low\", \"5m_close\", \"5m_volume\",\n",
    "    \"15m_open\", \"15m_high\", \"15m_low\", \"15m_close\", \"15m_volume\",\n",
    "    \"1h_open\", \"1h_high\", \"1h_low\", \"1h_close\", \"1h_volume\",\n",
    "    \"cross_tf_alignment_score\", \"cross_tf_alignment_direction\", \"cross_tf_alignment_strength\",\n",
    "    \"atr_percentile\",\n",
    "]\n",
    "\n",
    "def normalize_features(train_df, val_df=None, test_df=None):\n",
    "    cols = [c for c in FEATURE_COLUMNS if c in train_df.columns]\n",
    "    stats = {\"mean\": train_df[cols].mean().to_dict(), \"std\": train_df[cols].std().to_dict()}\n",
    "    for col in cols:\n",
    "        mean, std = stats[\"mean\"][col], stats[\"std\"][col]\n",
    "        if std > 0:\n",
    "            train_df[col] = (train_df[col] - mean) / std\n",
    "            if val_df is not None: val_df[col] = (val_df[col] - mean) / std\n",
    "            if test_df is not None: test_df[col] = (test_df[col] - mean) / std\n",
    "    logger.info(f\"Normalized {len(cols)} features\")\n",
    "    return train_df, val_df, test_df, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apps/trainer/train/dataset.py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from loguru import logger\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, df, feature_columns, sequence_length=60, prediction_horizon=15, prediction_type=\"direction\"):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.features = df[feature_columns].values.astype(np.float32)\n",
    "        self.sequence_length = sequence_length\n",
    "        future_close = df[\"close\"].shift(-prediction_horizon)\n",
    "        current_close = df[\"close\"]\n",
    "        self.targets = (future_close > current_close).astype(np.float32).values\n",
    "        self.valid_indices = np.arange(sequence_length, len(df) - prediction_horizon)\n",
    "        logger.info(f\"Dataset: {len(self.valid_indices)} sequences, {len(feature_columns)} features\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i = self.valid_indices[idx]\n",
    "        seq = self.features[i - self.sequence_length:i]\n",
    "        target = self.targets[i]\n",
    "        return torch.from_numpy(seq), torch.tensor([target], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile evaluate.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from loguru import logger\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from apps.trainer.models.lstm import LSTMModel\n",
    "from apps.trainer.data_pipeline import load_features_from_parquet, create_walk_forward_splits\n",
    "from apps.trainer.features import normalize_features, FEATURE_COLUMNS\n",
    "from apps.trainer.train.dataset import SequenceDataset\n",
    "\n",
    "def evaluate_model(model_path, symbol, device=\"cuda\", batch_size=64):\n",
    "    logger.info(f\"\\n{'='*60}\\nğŸš€ {symbol}\\n{'='*60}\")\n",
    "    df = load_features_from_parquet(symbol)\n",
    "    train_df, val_df, test_df = create_walk_forward_splits(df)\n",
    "    train_df, val_df, test_df, stats = normalize_features(train_df, val_df, test_df)\n",
    "    feature_cols = [c for c in FEATURE_COLUMNS if c in test_df.columns]\n",
    "    test_dataset = SequenceDataset(test_df, feature_columns=feature_cols)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=(device==\"cuda\"))\n",
    "    model = LSTMModel(input_size=len(feature_cols), hidden_size=128, num_layers=3, dropout=0.2, bidirectional=True)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model = model.to(device).eval()\n",
    "    logger.info(f\"Evaluating {len(test_dataset):,} sequences...\")\n",
    "    all_preds, all_targets, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (seqs, tgts) in enumerate(test_loader):\n",
    "            outs = model(seqs.to(device))\n",
    "            probs = outs.squeeze().cpu().numpy()\n",
    "            preds = (probs >= 0.5).astype(int)\n",
    "            all_probs.extend(probs.tolist() if probs.ndim > 0 else [probs.item()])\n",
    "            all_preds.extend(preds.tolist() if preds.ndim > 0 else [preds.item()])\n",
    "            all_targets.extend(tgts.squeeze().cpu().numpy().tolist())\n",
    "            if batch_idx % 100 == 0:\n",
    "                logger.info(f\"  {(batch_idx + 1) * batch_size:,}/{len(test_dataset):,}\")\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    prec = precision_score(all_targets, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_targets, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "    bins = np.linspace(0, 1, 11)\n",
    "    bin_idx = np.digitize(all_probs, bins) - 1\n",
    "    ece = 0.0\n",
    "    for i in range(10):\n",
    "        mask = bin_idx == i\n",
    "        if mask.sum() > 0:\n",
    "            ece += mask.sum() / len(all_targets) * abs(np.array(all_targets)[mask].mean() - np.array(all_probs)[mask].mean())\n",
    "    logger.info(f\"\\nâœ… Results: Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}, ECE={ece:.4f}\")\n",
    "    passes = acc >= 0.68 and ece <= 0.05\n",
    "    logger.info(f\"ğŸ¯ Gates: Accâ‰¥68% {'âœ…' if acc >= 0.68 else 'âŒ'} ({acc:.2%}), Calâ‰¤5% {'âœ…' if ece <= 0.05 else 'âŒ'} ({ece:.2%})\")\n",
    "    logger.info(f\"{'âœ… PASS' if passes else 'âŒ FAIL'}\\n\")\n",
    "    return {\"symbol\": symbol, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"calibration_error\": ece, \"num_samples\": len(all_targets)}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.info(f\"Device: {device}\")\n",
    "results = {}\n",
    "for symbol in [\"BTC-USD\", \"ETH-USD\", \"SOL-USD\"]:\n",
    "    model_path = f\"models/new/lstm_{symbol.replace('-', '_')}_1m_7b5f0829.pt\"\n",
    "    results[symbol] = evaluate_model(model_path, symbol, device=device)\n",
    "df = pd.DataFrame(results).T\n",
    "print(f\"\\n\\n{'='*60}\\nğŸ“Š SUMMARY\\n{'='*60}\\n{df.to_string()}\\n\")\n",
    "df.to_csv(\"results.csv\")\n",
    "logger.info(\"Saved: results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('results.csv')\n",
    "print(\"\\nâœ… Downloaded results.csv\")\n",
    "print(\"\\nShare this file in the Claude chat for analysis!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
