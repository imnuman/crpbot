#!/usr/bin/env python3
"""
V3 Ultimate - Master Orchestration Script
Runs all 5 steps sequentially on Google Colab Pro+

Total Runtime: ~49 hours
Requirements: Colab Pro+ with A100 GPU

Steps:
1. Data Collection (12h) - Fetch 5 years of OHLCV for 10 coins √ó 6 timeframes
2. Feature Engineering (4h) - Generate 270 features per candle
3. Train Ensemble (24h) - Train 5-model ensemble + meta-learner + calibration
4. Backtest (8h) - Validate on 5 years with 5,000+ trades
5. Export ONNX (1h) - Convert to ONNX and upload to S3

Usage:
    # Run all steps
    python 00_run_v3_ultimate.py

    # Run specific step
    python 00_run_v3_ultimate.py --step 1
    python 00_run_v3_ultimate.py --step 3

    # Resume from step N
    python 00_run_v3_ultimate.py --resume 3
"""

import sys
import subprocess
from pathlib import Path
from datetime import datetime
import json
import argparse

# Step definitions
STEPS = {
    1: {
        'name': 'Data Collection',
        'script': '01_fetch_data.py',
        'duration': 12,  # hours
        'description': 'Fetch 5 years of OHLCV data for 10 coins across 6 timeframes'
    },
    2: {
        'name': 'Feature Engineering',
        'script': '02_engineer_features.py',
        'duration': 4,
        'description': 'Generate 270 features per candle'
    },
    3: {
        'name': 'Train Ensemble',
        'script': '03_train_ensemble.py',
        'duration': 24,
        'description': 'Train 5-model ensemble + meta-learner + calibration'
    },
    4: {
        'name': 'Backtest',
        'script': '04_backtest.py',
        'duration': 8,
        'description': 'Validate on 5 years with realistic trading simulation'
    },
    5: {
        'name': 'Export ONNX',
        'script': '05_export_onnx.py',
        'duration': 1,
        'description': 'Convert to ONNX and upload to S3'
    }
}

def print_banner():
    """Print V3 Ultimate banner."""
    print("=" * 80)
    print(" " * 20 + "üöÄ V3 ULTIMATE - 5-MODEL ENSEMBLE")
    print("=" * 80)
    print()
    print("  Target Performance:")
    print("    ‚Ä¢ Win Rate: 75-78%")
    print("    ‚Ä¢ Sharpe Ratio: ‚â•1.8")
    print("    ‚Ä¢ Max Drawdown: >-12%")
    print("    ‚Ä¢ Trades: 5,000+")
    print()
    print("  Architecture:")
    print("    ‚Ä¢ XGBoost + LightGBM + CatBoost + TabNet + AutoML")
    print("    ‚Ä¢ Meta-learner stacking with calibration")
    print("    ‚Ä¢ 180 features selected from 270 engineered features")
    print()
    print("  Data:")
    print("    ‚Ä¢ 10 coins: BTC, ETH, SOL, BNB, ADA, XRP, MATIC, AVAX, DOGE, DOT")
    print("    ‚Ä¢ 6 timeframes: 1m, 5m, 15m, 1h, 4h, 1d")
    print("    ‚Ä¢ 5 years: 2020-01-01 to 2025-11-12")
    print()
    print("  Total Runtime: ~49 hours on Colab Pro+ A100")
    print("=" * 80)
    print()

def check_environment():
    """Check if running in appropriate environment."""
    print("üîç Checking environment...")

    # Check if in Colab
    try:
        import google.colab
        print("   ‚úÖ Running in Google Colab")
        in_colab = True
    except ImportError:
        print("   ‚ö†Ô∏è  Not running in Google Colab")
        in_colab = False

    # Check GPU
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"   ‚úÖ GPU: {gpu_name} ({gpu_memory:.1f}GB)")

            if 'A100' in gpu_name:
                print("   ‚úÖ A100 GPU detected - optimal performance")
            else:
                print("   ‚ö†Ô∏è  Not A100 - training may be slower")
        else:
            print("   ‚ùå No GPU detected!")
            return False
    except ImportError:
        print("   ‚ö†Ô∏è  PyTorch not installed, cannot check GPU")

    # Check Google Drive
    if in_colab:
        drive_path = Path('/content/drive/MyDrive')
        if drive_path.exists():
            print("   ‚úÖ Google Drive mounted")
        else:
            print("   ‚ùå Google Drive not mounted!")
            print("      Run: from google.colab import drive; drive.mount('/content/drive')")
            return False

    return True

def run_step(step_num):
    """Run a single step."""
    if step_num not in STEPS:
        print(f"‚ùå Invalid step number: {step_num}")
        return False

    step = STEPS[step_num]

    print()
    print("=" * 80)
    print(f"üöÄ STEP {step_num}: {step['name']}")
    print("=" * 80)
    print(f"Description: {step['description']}")
    print(f"Estimated Duration: {step['duration']} hours")
    print(f"Script: {step['script']}")
    print()

    start_time = datetime.now()

    # Run the step script
    script_path = Path(__file__).parent / step['script']

    if not script_path.exists():
        print(f"‚ùå Script not found: {script_path}")
        return False

    try:
        print(f"‚ñ∂Ô∏è  Starting {step['script']}...")
        print()

        result = subprocess.run(
            [sys.executable, str(script_path)],
            check=True,
            text=True
        )

        duration = (datetime.now() - start_time).total_seconds() / 3600

        print()
        print("=" * 80)
        print(f"‚úÖ STEP {step_num} COMPLETE")
        print("=" * 80)
        print(f"Duration: {duration:.2f} hours (estimated: {step['duration']}h)")
        print()

        return True

    except subprocess.CalledProcessError as e:
        duration = (datetime.now() - start_time).total_seconds() / 3600

        print()
        print("=" * 80)
        print(f"‚ùå STEP {step_num} FAILED")
        print("=" * 80)
        print(f"Duration: {duration:.2f} hours")
        print(f"Error: {e}")
        print()

        return False

def run_all_steps(start_from=1):
    """Run all steps from start_from to end."""
    print_banner()

    if not check_environment():
        print("\n‚ùå Environment check failed. Please fix issues above.")
        return False

    print(f"\nüöÄ Starting V3 Ultimate pipeline from Step {start_from}...")
    print()

    pipeline_start = datetime.now()
    results = {}

    for step_num in range(start_from, 6):
        success = run_step(step_num)
        results[step_num] = success

        if not success:
            print(f"\n‚ùå Pipeline failed at Step {step_num}")
            print(f"   To resume from this step, run:")
            print(f"   python 00_run_v3_ultimate.py --resume {step_num}")
            return False

        # Save checkpoint
        checkpoint = {
            'timestamp': datetime.now().isoformat(),
            'last_completed_step': step_num,
            'results': results
        }

        checkpoint_path = Path('/content/drive/MyDrive/crpbot/v3_ultimate_checkpoint.json')
        checkpoint_path.parent.mkdir(parents=True, exist_ok=True)

        with open(checkpoint_path, 'w') as f:
            json.dump(checkpoint, f, indent=2)

        print(f"üíæ Checkpoint saved: {checkpoint_path}")

    pipeline_duration = (datetime.now() - pipeline_start).total_seconds() / 3600

    # Final summary
    print()
    print("=" * 80)
    print("üéâ V3 ULTIMATE PIPELINE COMPLETE!")
    print("=" * 80)
    print(f"\nTotal Duration: {pipeline_duration:.1f} hours")
    print(f"\nSteps Completed:")

    for step_num, success in results.items():
        status = "‚úÖ" if success else "‚ùå"
        print(f"   {status} Step {step_num}: {STEPS[step_num]['name']}")

    print()
    print("üì¶ Deliverables:")
    print("   ‚Ä¢ /content/drive/MyDrive/crpbot/models/metadata.json")
    print("   ‚Ä¢ /content/drive/MyDrive/crpbot/models/*.pkl (6 models)")
    print("   ‚Ä¢ /content/drive/MyDrive/crpbot/models/onnx/*.onnx (5 ONNX models)")
    print("   ‚Ä¢ /content/drive/MyDrive/crpbot/backtest/backtest_summary.json")
    print("   ‚Ä¢ /content/drive/MyDrive/crpbot/backtest/backtest_results.csv")
    print()
    print("üöÄ Next Steps:")
    print("   1. Download models from Google Drive")
    print("   2. Verify validation gates passed")
    print("   3. Deploy to production infrastructure")
    print("   4. Start paper trading")
    print()

    return True

def main():
    """Main orchestration entry point."""
    parser = argparse.ArgumentParser(description='V3 Ultimate - Master Orchestration')
    parser.add_argument('--step', type=int, help='Run specific step (1-5)')
    parser.add_argument('--resume', type=int, help='Resume from step N')

    args = parser.parse_args()

    if args.step:
        # Run single step
        print_banner()
        if not check_environment():
            print("\n‚ùå Environment check failed.")
            sys.exit(1)

        success = run_step(args.step)
        sys.exit(0 if success else 1)

    elif args.resume:
        # Resume from step
        success = run_all_steps(start_from=args.resume)
        sys.exit(0 if success else 1)

    else:
        # Run all steps
        success = run_all_steps(start_from=1)
        sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
