# Database Schema Documentation

**Last Updated**: 2025-11-21
**Database**: SQLite (`tradingai.db`)
**Location**: `/root/crpbot/tradingai.db`

---

## Overview

The trading bot uses SQLite for persistent storage of signals, performance results, patterns, and model deployments. All tables are defined in `libs/db/models.py` using SQLAlchemy ORM.

---

## Table of Contents

1. [signals](#signals-table) - Trading signals generated by V7
2. [signal_results](#signal_results-table) - Paper trading performance tracking
3. [theory_performance](#theory_performance-table) - Individual theory contributions
4. [patterns](#patterns-table) - Auto-learning pattern tracking
5. [risk_book_snapshots](#risk_book_snapshots-table) - Trade execution tracking
6. [model_deployments](#model_deployments-table) - ML model version tracking

---

## `signals` Table

**Purpose**: Stores all trading signals generated by the V7 system.

**Primary Key**: `id` (INTEGER, autoincrement)

### Schema

| Column | Type | Nullable | Default | Index | Description |
|--------|------|----------|---------|-------|-------------|
| `id` | INTEGER | No | Auto | Primary Key | Unique signal ID |
| `timestamp` | DATETIME | No | now() | Yes | Signal generation time (UTC) |
| `symbol` | VARCHAR(20) | No | - | Yes | Trading pair (e.g., BTC-USD) |
| `direction` | VARCHAR(10) | No | - | No | 'long', 'short', or 'hold' |
| `confidence` | FLOAT | No | - | No | Model confidence (0.0-1.0) |
| `tier` | VARCHAR(10) | No | - | Yes | 'high', 'medium', 'low' |
| `lstm_prediction` | FLOAT | Yes | NULL | No | LSTM model output |
| `transformer_prediction` | FLOAT | Yes | NULL | No | Transformer model output |
| `rl_prediction` | FLOAT | Yes | NULL | No | RL model output |
| `ensemble_prediction` | FLOAT | No | - | No | Final ensemble prediction |
| `session` | VARCHAR(20) | Yes | NULL | No | Trading session (tokyo/london/new_york) |
| `entry_price` | FLOAT | Yes | NULL | No | Recommended entry price |
| `tp_price` | FLOAT | Yes | NULL | No | Take profit price |
| `sl_price` | FLOAT | Yes | NULL | No | Stop loss price |
| `executed` | INTEGER | Yes | 0 | No | 0=not executed, 1=executed |
| `execution_time` | DATETIME | Yes | NULL | No | When trade was executed |
| `execution_price` | FLOAT | Yes | NULL | No | Actual execution price |
| `result` | VARCHAR(10) | Yes | NULL | No | 'win', 'loss', 'pending', 'skipped' |
| `exit_time` | DATETIME | Yes | NULL | No | When trade exited |
| `exit_price` | FLOAT | Yes | NULL | No | Exit price |
| `pnl` | FLOAT | Yes | NULL | No | Profit/loss |
| `latency_ms` | FLOAT | Yes | NULL | No | Signal generation latency |
| `model_version` | VARCHAR(20) | Yes | NULL | No | Model version used |
| `notes` | TEXT | Yes | NULL | No | Additional notes |
| `strategy` | VARCHAR(50) | Yes | 'v7_full_math' | No | 'v7_full_math' or 'v7_deepseek_only' (A/B testing) |

### Example Query

```sql
-- Get recent high-confidence signals
SELECT id, timestamp, symbol, direction, confidence, entry_price
FROM signals
WHERE tier = 'high' AND confidence > 0.65
ORDER BY timestamp DESC
LIMIT 10;
```

---

## `signal_results` Table

**Purpose**: Tracks paper trading results for performance analysis. This table is used by the dashboard's Performance and A/B Test pages.

**Primary Key**: `id` (INTEGER, autoincrement)
**Foreign Key**: `signal_id` → `signals.id`

### Schema

| Column | Type | Nullable | Default | Index | Description |
|--------|------|----------|---------|-------|-------------|
| `id` | INTEGER | No | Auto | Primary Key | Unique result ID |
| `signal_id` | INTEGER | No | - | Unique Index | Links to signals table |
| `entry_price` | FLOAT | No | - | No | Virtual entry price |
| `entry_timestamp` | DATETIME | No | - | Yes | When position opened |
| `exit_price` | FLOAT | Yes | NULL | No | Virtual exit price |
| `exit_timestamp` | DATETIME | Yes | NULL | Yes | When position closed |
| `exit_reason` | VARCHAR(50) | Yes | NULL | No | 'tp_hit', 'sl_hit', 'manual', 'timeout' |
| `pnl_percent` | FLOAT | Yes | NULL | No | P&L percentage |
| `pnl_usd` | FLOAT | Yes | NULL | No | P&L in USD |
| `outcome` | VARCHAR(20) | No | 'open' | Yes | 'open', 'win', 'loss', 'breakeven' |
| `hold_duration_minutes` | INTEGER | Yes | NULL | No | How long position was held |
| `created_at` | DATETIME | No | now() | No | Record creation time |
| `updated_at` | DATETIME | No | now() | No | Last update time |

### Indexes

- `idx_signal_outcome` on (`signal_id`, `outcome`)
- `idx_entry_timestamp` on (`entry_timestamp`)
- `idx_exit_timestamp` on (`exit_timestamp`)

### Example Query

```sql
-- Calculate win rate for last 30 days
SELECT
    COUNT(*) as total_trades,
    SUM(CASE WHEN outcome = 'win' THEN 1 ELSE 0 END) as wins,
    CAST(SUM(CASE WHEN outcome = 'win' THEN 1 ELSE 0 END) AS FLOAT) / COUNT(*) * 100 as win_rate_pct,
    AVG(pnl_percent) as avg_pnl_pct
FROM signal_results
WHERE outcome IN ('win', 'loss', 'breakeven')
  AND exit_timestamp >= datetime('now', '-30 days');
```

---

## `theory_performance` Table

**Purpose**: Tracks how individual mathematical theories contribute to each signal's success.

**Primary Key**: `id` (INTEGER, autoincrement)
**Foreign Key**: `signal_id` → `signals.id`

### Schema

| Column | Type | Nullable | Default | Index | Description |
|--------|------|----------|---------|-------|-------------|
| `id` | INTEGER | No | Auto | Primary Key | Unique record ID |
| `signal_id` | INTEGER | No | - | Yes | Links to signals table |
| `theory_name` | VARCHAR(100) | No | - | Yes | Theory name (e.g., 'shannon_entropy') |
| `contribution_score` | FLOAT | No | - | No | How strongly theory influenced signal (0.0-1.0) |
| `was_correct` | BOOLEAN | Yes | NULL | Yes | Whether theory's prediction was correct |
| `created_at` | DATETIME | No | now() | No | Record creation time |

### Indexes

- `idx_signal_theory` on (`signal_id`, `theory_name`)
- `idx_theory_correct` on (`theory_name`, `was_correct`)

### Example Query

```sql
-- Find best-performing theories
SELECT
    theory_name,
    COUNT(*) as total_signals,
    SUM(CASE WHEN was_correct = 1 THEN 1 ELSE 0 END) as correct_predictions,
    CAST(SUM(CASE WHEN was_correct = 1 THEN 1 ELSE 0 END) AS FLOAT) / COUNT(*) * 100 as accuracy_pct,
    AVG(contribution_score) as avg_contribution
FROM theory_performance
WHERE was_correct IS NOT NULL
GROUP BY theory_name
ORDER BY accuracy_pct DESC;
```

---

## `patterns` Table

**Purpose**: Auto-learning system that tracks recurring price patterns and their success rates.

**Primary Key**: `id` (INTEGER, autoincrement)

### Schema

| Column | Type | Nullable | Default | Index | Description |
|--------|------|----------|---------|-------|-------------|
| `id` | INTEGER | No | Auto | Primary Key | Unique pattern ID |
| `name` | VARCHAR(255) | No | - | Yes | Human-readable pattern name |
| `pattern_hash` | VARCHAR(64) | No | - | Unique Index | SHA-256 hash of pattern features |
| `wins` | INTEGER | No | 0 | No | Number of winning trades |
| `total` | INTEGER | No | 0 | No | Total number of trades |
| `win_rate` | FLOAT | No | 0.0 | No | win_rate = wins / total |
| `created_at` | DATETIME | No | now() | No | First seen timestamp |
| `updated_at` | DATETIME | No | now() | No | Last update timestamp |

### Example Query

```sql
-- Find high-probability patterns
SELECT name, wins, total, win_rate
FROM patterns
WHERE total >= 10 AND win_rate >= 0.65
ORDER BY win_rate DESC, total DESC;
```

---

## `risk_book_snapshots` Table

**Purpose**: Tracks trade execution details for risk management and performance analysis.

**Primary Key**: `signal_id` (VARCHAR(64))

### Schema

| Column | Type | Nullable | Default | Index | Description |
|--------|------|----------|---------|-------|-------------|
| `signal_id` | VARCHAR(64) | No | - | Primary Key | Unique signal identifier |
| `pair` | VARCHAR(20) | No | - | Yes | Trading pair |
| `tier` | VARCHAR(10) | No | - | Yes | Signal tier |
| `entry_time` | DATETIME | No | - | Yes | Entry timestamp |
| `entry_price` | FLOAT | No | - | No | Entry price |
| `tp_price` | FLOAT | Yes | NULL | No | Take profit price |
| `sl_price` | FLOAT | Yes | NULL | No | Stop loss price |
| `rr_expected` | FLOAT | Yes | NULL | No | Expected risk/reward ratio |
| `result` | VARCHAR(10) | Yes | NULL | Yes | 'win', 'loss', or NULL |
| `exit_time` | DATETIME | Yes | NULL | No | Exit timestamp |
| `exit_price` | FLOAT | Yes | NULL | No | Exit price |
| `r_realized` | FLOAT | Yes | NULL | No | Realized R-multiple |
| `time_to_tp_sl_seconds` | INTEGER | Yes | NULL | No | Time to hit TP/SL |
| `slippage_bps` | FLOAT | Yes | NULL | No | Slippage in basis points |
| `slippage_expected_bps` | FLOAT | Yes | NULL | No | Expected slippage |
| `spread_bps` | FLOAT | Yes | NULL | No | Bid-ask spread |
| `latency_ms` | FLOAT | Yes | NULL | No | Execution latency |
| `mode` | VARCHAR(10) | No | - | Yes | 'dryrun' or 'live' |
| `created_at` | DATETIME | No | now() | No | Record creation time |

### Indexes

- `idx_entry_time` on (`entry_time`)
- `idx_pair_mode` on (`pair`, `mode`)
- `idx_result_mode` on (`result`, `mode`)

---

## `model_deployments` Table

**Purpose**: Tracks ML model versions, metrics, and deployment history.

**Primary Key**: `id` (INTEGER, autoincrement)

### Schema

| Column | Type | Nullable | Default | Index | Description |
|--------|------|----------|---------|-------|-------------|
| `id` | INTEGER | No | Auto | Primary Key | Unique deployment ID |
| `version` | VARCHAR(50) | No | - | Unique Index | Model version string |
| `model_path` | VARCHAR(500) | No | - | No | Path to model file |
| `model_type` | VARCHAR(50) | No | - | No | 'lstm', 'transformer', 'ensemble' |
| `deployed_at` | DATETIME | No | now() | Yes | Deployment timestamp |
| `metrics_json` | JSON | Yes | NULL | No | Training metrics (accuracy, loss, etc.) |
| `rollback_reason` | TEXT | Yes | NULL | No | Why model was rolled back |
| `is_promoted` | BOOLEAN | No | False | Yes | Is this the promoted/production model? |
| `is_active` | BOOLEAN | No | True | Yes | Is this model currently active? |

### Example Query

```sql
-- Get current production models
SELECT version, model_type, deployed_at, metrics_json
FROM model_deployments
WHERE is_promoted = 1 AND is_active = 1
ORDER BY deployed_at DESC;
```

---

## Common Queries

### Performance Dashboard Queries

```sql
-- Get overall win rate (last 30 days)
SELECT
    COUNT(*) as total_trades,
    SUM(CASE WHEN outcome = 'win' THEN 1 ELSE 0 END) as wins,
    SUM(CASE WHEN outcome = 'loss' THEN 1 ELSE 0 END) as losses,
    CAST(SUM(CASE WHEN outcome = 'win' THEN 1 ELSE 0 END) AS FLOAT) / COUNT(*) * 100 as win_rate,
    AVG(CASE WHEN outcome = 'win' THEN pnl_percent END) as avg_win_pct,
    AVG(CASE WHEN outcome = 'loss' THEN pnl_percent END) as avg_loss_pct,
    AVG(pnl_percent) as avg_pnl_pct
FROM signal_results sr
WHERE outcome IN ('win', 'loss', 'breakeven')
  AND exit_timestamp >= datetime('now', '-30 days');

-- Get open positions
SELECT
    sr.signal_id,
    s.symbol,
    s.direction,
    sr.entry_price,
    sr.entry_timestamp,
    s.tp_price,
    s.sl_price
FROM signal_results sr
JOIN signals s ON sr.signal_id = s.id
WHERE sr.outcome = 'open'
ORDER BY sr.entry_timestamp DESC;

-- A/B Test comparison (v7_full_math vs v7_deepseek_only)
SELECT
    s.strategy,
    COUNT(*) as total_trades,
    SUM(CASE WHEN sr.outcome = 'win' THEN 1 ELSE 0 END) as wins,
    CAST(SUM(CASE WHEN sr.outcome = 'win' THEN 1 ELSE 0 END) AS FLOAT) / COUNT(*) * 100 as win_rate,
    AVG(sr.pnl_percent) as avg_pnl_pct
FROM signal_results sr
JOIN signals s ON sr.signal_id = s.id
WHERE sr.outcome IN ('win', 'loss', 'breakeven')
  AND sr.exit_timestamp >= datetime('now', '-30 days')
GROUP BY s.strategy;
```

---

## Database Maintenance

### Creating Tables

Tables are automatically created when the application starts if they don't exist. To manually create all tables:

```python
from libs.db.models import create_tables
create_tables()  # Uses default DB_URL from .env
```

Or use the migration script:

```bash
.venv/bin/python3 scripts/create_missing_tables.py
```

### Backing Up Database

```bash
# Create backup
cp tradingai.db tradingai_backup_$(date +%Y%m%d_%H%M%S).db

# Restore from backup
cp tradingai_backup_20251121_160000.db tradingai.db
```

### Checking Database Size

```bash
ls -lh tradingai.db
```

### Vacuum Database (Optimize)

```python
import sqlite3
conn = sqlite3.connect('tradingai.db')
conn.execute('VACUUM')
conn.close()
```

---

## Troubleshooting

### Problem: Dashboard shows blank Performance or A/B Test pages

**Cause**: The `signal_results` or `theory_performance` tables are missing.

**Solution**:

```bash
# 1. Check if tables exist
.venv/bin/python3 -c "
import sqlite3
conn = sqlite3.connect('tradingai.db')
cursor = conn.cursor()
cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name IN ('signal_results', 'theory_performance')\")
print(cursor.fetchall())
conn.close()
"

# 2. If tables are missing, create them
.venv/bin/python3 scripts/create_missing_tables.py

# 3. Restart V7 runtime and dashboard
ps aux | grep v7_runtime | grep -v grep | awk '{print $2}' | xargs -r kill -9
# Start V7 again...
```

### Problem: `sqlite3.OperationalError: no such table: signal_results`

**Cause**: The table was not created when the database was initialized.

**Solution**: Run the migration script (see above).

### Problem: Paper trading not tracking results

**Cause**: V7 runtime is not configured to use the paper trading system.

**Solution**: Check that the performance tracker is being called in the V7 runtime (`apps/runtime/v7_runtime.py`).

---

## References

- **Models Definition**: `libs/db/models.py`
- **Performance Tracker**: `libs/tracking/performance_tracker.py`
- **Migration Script**: `scripts/create_missing_tables.py`
- **V7 Runtime**: `apps/runtime/v7_runtime.py`

---

**Version**: 1.0
**Date**: 2025-11-21
