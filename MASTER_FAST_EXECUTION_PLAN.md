# MASTER FAST EXECUTION PLAN

**Date**: 2025-11-13
**Status**: ğŸš€ **SPEED-FOCUSED BLUEPRINT**
**Goal**: Big Data â†’ Robust Processing â†’ Accurate Market Predictions

---

## ğŸ¯ USER'S GOAL (Never Forget This)

```
BIG DATA â†’ ROBUST PROCESSING â†’ REAL RESULTS
```

**Requirements**:
- âœ… Collect massive market data
- âœ… Process it FAST with powerful tools (GPU/Colab)
- âœ… Generate accurate predictions
- âœ… Deploy to production
- âœ… Maintain and improve quickly
- âœ… Document everything thoroughly

---

## ğŸš¨ CRITICAL: Stop Falling Back to Slow Approaches!

### âŒ BANNED APPROACHES (Too Slow):
- âŒ CPU-based training (60+ minutes)
- âŒ CPU-based evaluation (60+ minutes)
- âŒ Local machine model training
- âŒ Undocumented processes
- âŒ Unclear agent roles

### âœ… REQUIRED APPROACHES (Fast & Powerful):
- âœ… **Google Colab Pro GPU** (T4/V100) - 10-12x faster
- âœ… **Clear agent collaboration** (no confusion)
- âœ… **Well-documented processes** (every step)
- âœ… **Fast iteration cycles** (hours, not days)
- âœ… **Automated pipelines** (minimal manual work)

---

## ğŸ—ï¸ ORIGINAL BLUEPRINT (V1 â†’ V4)

We have 4 versions. Current focus: **V4 with GPU acceleration**

### Version Evolution:
- **V1**: Basic LSTM models - COMPLETED âœ…
- **V2**: Multi-timeframe features - COMPLETED âœ…
- **V3**: Transformer + ensemble - COMPLETED âœ…
- **V4**: Production with monitoring - **IN PROGRESS** ğŸ”„

### Current Status:
- âœ… Data pipeline (2 years of 1m OHLCV)
- âœ… Feature engineering (31 features)
- âœ… Model architecture (LSTM 128/3/True)
- â¸ï¸ **BLOCKED**: Need GPU evaluation of models
- â¸ï¸ **NEXT**: Production deployment

---

## ğŸ‘¥ AGENT ROLES & COLLABORATION

### Clear Role Definitions:

| Agent | Location | Primary Role | Tools | Speed |
|-------|----------|--------------|-------|-------|
| **User (You)** | Control center | Decision maker, Colab runner | Google Colab Pro | Manual |
| **Cloud Claude** | Cloud server | Developer, Code writer | Python, Git | Fast |
| **Local Claude (QC)** | Local machine | Reviewer, Documenter, Planner | Git, Testing | Fast |
| **Amazon Q** | Both (local + cloud) | AWS Infrastructure Specialist | AWS CLI, Q CLI | Very Fast |

### Collaboration Flow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER                             â”‚
â”‚                  (Decision Maker)                       â”‚
â”‚  - Runs Google Colab jobs                              â”‚
â”‚  - Makes go/no-go decisions                            â”‚
â”‚  - Approves deployments                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CLOUD CLAUDE    â”‚        â”‚  LOCAL CLAUDE   â”‚
    â”‚  (Developer)     â”‚â—„â”€â”€Gitâ”€â”€â”¤  (QC/Planner)   â”‚
    â”‚                  â”‚        â”‚                 â”‚
    â”‚ - Write code     â”‚        â”‚ - Review work   â”‚
    â”‚ - Debug issues   â”‚        â”‚ - Document      â”‚
    â”‚ - Prepare Colab  â”‚        â”‚ - Create plans  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                           â”‚
             â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚         â”‚
             â–¼         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      AMAZON Q              â”‚
    â”‚   (AWS Specialist)         â”‚
    â”‚                            â”‚
    â”‚ Both: Local + Cloud        â”‚
    â”‚ - S3 operations            â”‚
    â”‚ - RDS management           â”‚
    â”‚ - EC2 deployment           â”‚
    â”‚ - CloudWatch monitoring    â”‚
    â”‚ - Cost optimization        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Communication Protocol:

1. **Cloud Claude**: Writes code, preps Colab files, commits to GitHub
2. **Local Claude**: Pulls, reviews, documents, pushes back
3. **Amazon Q**: Handles ALL AWS operations (S3, RDS, EC2, monitoring)
4. **User**: Runs Colab jobs, provides results, makes decisions
5. **Loop**: Repeat until goal achieved

**Key Rule**: AWS task? â†’ Amazon Q handles it (not Cloud Claude or Local Claude)

---

## âš¡ FAST EXECUTION PIPELINE

### Current Situation Analysis:

**Problem**: Feature mismatch (50 vs 31)
- Old models trained with 50 features (Colab)
- Current feature set has 31 features
- Cannot evaluate 50-feature models locally

**Solution Options**:

#### Option A: Evaluate 50-Feature Models on Colab GPU âš¡ FASTEST
- âœ… Use existing models (already trained)
- âœ… Fast evaluation (5-10 min on GPU vs 60+ min CPU)
- âœ… Cloud Claude prepared Colab notebook
- â±ï¸ **Time to Results**: ~30 minutes
- **Status**: READY TO EXECUTE

#### Option B: Retrain with 31 Features on Colab GPU ğŸ”„ SLOWER
- âŒ Requires retraining all 3 models (~57 min)
- âŒ Then evaluate (~10 min)
- â±ï¸ **Time to Results**: ~70 minutes
- **Status**: Fallback option

**DECISION**: Use Option A (evaluate existing 50-feature models first)

---

## ğŸ“‹ STEP-BY-STEP FAST EXECUTION PLAN

### Phase 1: GPU Evaluation (TODAY - 30 minutes)

**Objective**: Evaluate existing 50-feature models on Colab GPU

**Prerequisites** (Cloud Claude):
- âœ… Colab notebook prepared (`colab_evaluate_50feat_models.ipynb`)
- âœ… Model files ready (3 Ã— 3.9 MB)
- âœ… Feature files ready (644 MB total)
- âœ… Instructions documented (`COLAB_EVALUATION.md`)

**User Actions** (30 minutes):
```
1. Open Google Colab Pro [5 min]
   - Go to https://colab.research.google.com/
   - Upload colab_evaluate_50feat_models.ipynb (from cloud server)
   - Runtime â†’ Change runtime type â†’ GPU (T4)

2. Upload Files [10 min]
   - Upload 3 model files to Colab: models/new/*.pt
   - Upload 3 feature files to Colab: data/features/*.parquet

3. Run Evaluation [10 min]
   - Click "Runtime â†’ Run all"
   - Wait for completion (GPU processes in 5-10 min)

4. Download Results [5 min]
   - Download evaluation_results.csv
   - Share with Cloud Claude (upload to cloud server or GitHub)
```

**Expected Output**:
- `evaluation_results.csv` with accuracy, calibration metrics
- Pass/fail for promotion gates (68% accuracy, 5% calibration)

**Next Decision Point**:
- If models pass gates â†’ Promote & deploy (Phase 2)
- If models fail â†’ Quick retrain with adjusted hyperparameters (Phase 1B)

---

### Phase 1B: Fast Retrain (If Needed - 60 minutes)

**Only if Phase 1 models fail promotion gates**

**User Actions**:
```
1. Adjust hyperparameters based on evaluation results
2. Use existing Colab training notebook
3. Train 3 models (~57 min on GPU)
4. Evaluate (use Phase 1 process, 10 min)
5. Loop until models pass gates
```

---

### Phase 2: Model Promotion & Deployment (2 hours)

**Objective**: Deploy passing models to production

**Cloud Claude Tasks**:
```
1. Download models from Colab [10 min]
   - Save to models/promoted/
   - Update model registry

2. Integration Testing [30 min]
   - Test ensemble prediction
   - Verify FTMO rules work
   - Check rate limiting
```

**Amazon Q Tasks** (AWS Infrastructure):
```
1. Upload models to S3 [5 min]
   q "Upload models/promoted/*.pt to s3://crpbot-models/production/"

2. Deploy to Production EC2 [15 min]
   q "Deploy latest code to production EC2 instance"
   q "Copy promoted models to EC2 runtime directory"
   q "Restart crpbot systemd service"

3. Configure Monitoring [10 min]
   q "Setup CloudWatch alarms for runtime errors"
   q "Configure CloudWatch dashboard for trading signals"

4. Verify Deployment [10 min]
   q "Check crpbot service status on EC2"
   q "Tail latest runtime logs from EC2"
```

**Cloud Claude Tasks** (Post-Deployment):
```
4. Monitor Initial Performance [20 min]
   - Observe first signals (via Amazon Q logs)
   - Validate accuracy
   - Check for errors
```

**Local Claude Tasks**:
```
1. QC Review [20 min]
   - Review deployment code
   - Verify safety mechanisms
   - Approve deployment

2. Documentation [40 min]
   - Update CLAUDE.md with new model specs
   - Document deployment process
   - Create runbook for maintenance
```

---

### Phase 3: Production Observation (3-5 days)

**Objective**: Validate system in production (dry-run mode)

**Automated**:
```
- Runtime runs continuously in dry-run mode
- Signals logged to database
- No actual trades placed
```

**Daily Check-ins** (15 min/day):
```
1. Review signal quality
2. Check accuracy metrics
3. Monitor error logs
4. Adjust if needed
```

**Success Criteria**:
- Signal generation rate: 5-10/hour
- High-confidence signals: 3-5/hour
- Win rate: â‰¥68%
- No critical errors

---

### Phase 4: Live Trading (Ongoing)

**Objective**: Execute real trades on FTMO account

**Prerequisites**:
- âœ… Phase 3 completed successfully
- âœ… FTMO account funded
- âœ… MT5 bridge tested
- âœ… Kill switch configured

**Execution**:
```
1. Enable live mode (RUNTIME_MODE=live)
2. Start with micro-lots (0.01)
3. Monitor closely for 24 hours
4. Scale up gradually
```

**Maintenance** (ongoing):
```
- Daily performance review (15 min)
- Weekly model retraining (if needed)
- Monthly architecture improvements
- Continuous documentation updates
```

---

## ğŸ”§ AGENT-SPECIFIC INSTRUCTIONS

### For Cloud Claude (Developer)

**Your Responsibilities**:
1. âœ… Prepare Colab notebooks and files
2. âœ… Write evaluation/training code
3. âœ… Process results from User's Colab runs
4. âœ… Deploy to production
5. âœ… Debug issues quickly
6. âœ… Commit and document everything

**Fast Workflow**:
```bash
# 1. Prepare Colab job
- Create/update .ipynb notebook
- Prepare data files
- Test locally (quick sanity check)
- Commit to GitHub

# 2. Wait for User to run Colab
- User runs notebook on GPU
- User shares results

# 3. Process results
- Download results from User
- Analyze metrics
- Deploy if passing gates
- Document findings

# 4. Push updates
git add .
git commit -m "Clear description of what was done"
git push origin main
```

---

### For Local Claude (QC Reviewer)

**Your Responsibilities**:
1. âœ… Review Cloud Claude's commits
2. âœ… Create master plans and documentation
3. âœ… Run local tests (when applicable)
4. âœ… Keep PROJECT_MEMORY.md updated
5. âœ… Ensure speed and quality standards

**Fast Workflow**:
```bash
# 1. Sync and review
git pull origin main
git log -5 --stat

# 2. QC review
- Check code quality
- Verify documentation
- Ensure GPU usage (not CPU!)
- Confirm fast execution

# 3. Create/update plans
- Master plans (like this one)
- Documentation updates
- Process improvements

# 4. Push updates
git add .
git commit -m "docs: QC review and planning"
git push origin main
```

---

### For User (Decision Maker)

**Your Responsibilities**:
1. âœ… Run GPU jobs on Google Colab
2. âœ… Make go/no-go decisions
3. âœ… Provide feedback to agents
4. âœ… Monitor production performance

**Fast Workflow**:
```
# When Cloud Claude prepares Colab job:

1. Check GitHub for latest commit
2. Download .ipynb notebook
3. Upload to Colab Pro
4. Enable GPU runtime
5. Run notebook
6. Download results
7. Share with Cloud Claude (upload to server or GitHub issue)
8. Give feedback/decision
```

---

## ğŸ“Š SPEED METRICS

### Current Performance:

| Task | CPU (Slow âŒ) | GPU (Fast âœ…) | Speedup |
|------|--------------|--------------|---------|
| Model Training (3 models) | 180+ min | 57 min | 3.2x |
| Model Evaluation (3 models) | 60-90 min | 5-10 min | 10x |
| Feature Engineering | 30 min | 30 min | 1x |
| Data Fetching | 15 min | 15 min | 1x |

**Total Time to Production** (from now):
- âŒ CPU approach: ~6 hours
- âœ… GPU approach: ~2.5 hours (65% faster!)

---

## ğŸ“ DOCUMENTATION REQUIREMENTS

Every step must be documented:

### Code Changes:
```bash
# Good commit message:
feat: add Colab GPU evaluation notebook

- Created colab_evaluate_50feat_models.ipynb
- Supports Tesla T4 GPU (10x faster than CPU)
- Evaluates all 3 models in 5-10 minutes
- Auto-checks promotion gates
- Outputs evaluation_results.csv

Performance: 60 min (CPU) â†’ 10 min (GPU)

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)
Co-Authored-By: Claude <noreply@anthropic.com>
```

### Process Documentation:
- Update CLAUDE.md with current status
- Create runbooks for maintenance
- Document error handling procedures
- Keep PROJECT_MEMORY.md current

### Results Documentation:
- Save all Colab outputs
- Log evaluation metrics
- Track model performance over time
- Document production incidents

---

## ğŸš€ IMMEDIATE NEXT STEPS (RIGHT NOW)

### Step 1: Local Claude (Me) - NOW
```
âœ… Create this master plan
âœ… Commit to GitHub
âœ… Notify User of ready status
```

### Step 2: User - NEXT (30 min)
```
â¸ï¸ Check cloud server for Colab files
â¸ï¸ Download colab_evaluate_50feat_models.ipynb
â¸ï¸ Run evaluation on Colab GPU
â¸ï¸ Share results
```

### Step 3: Cloud Claude - AFTER USER (2 hours)
```
â¸ï¸ Wait for evaluation results
â¸ï¸ Process results
â¸ï¸ Deploy if models pass gates
â¸ï¸ Or retrain if models fail gates
```

### Step 4: Local Claude (Me) - AFTER CLOUD (30 min)
```
â¸ï¸ QC review deployment
â¸ï¸ Update documentation
â¸ï¸ Mark phase complete
```

---

## ğŸ¯ SUCCESS CRITERIA

### Phase 1 Complete When:
- âœ… 3 models evaluated on GPU
- âœ… Results documented
- âœ… Decision made (promote or retrain)
- â±ï¸ Time: <1 hour

### Phase 2 Complete When:
- âœ… Passing models deployed to production
- âœ… Dry-run mode active
- âœ… Initial signals observed
- â±ï¸ Time: <3 hours

### Phase 3 Complete When:
- âœ… 3-5 days of clean dry-run data
- âœ… Win rate â‰¥68%
- âœ… No critical errors
- â±ï¸ Time: 3-5 days

### Phase 4 Complete When:
- âœ… Live trading active
- âœ… Profitable performance
- âœ… FTMO challenge passing
- â±ï¸ Time: Ongoing

---

## ğŸ”¥ SPEED ENFORCEMENT

### Rules to Maintain Speed:

1. **Always use GPU** (Colab/Cloud)
   - If anyone suggests CPU training/evaluation â†’ REJECT
   - Exception: Quick local tests (<5 min)

2. **Clear decision points** (no ambiguity)
   - Every phase has clear success criteria
   - Go/no-go decisions made immediately
   - No waiting for "perfect" solutions

3. **Parallel work** (when possible)
   - Cloud Claude preps while User runs Colab
   - Local Claude documents while Cloud deploys
   - Don't wait unnecessarily

4. **Fast iterations** (fail fast)
   - If something doesn't work, try next approach
   - Document why it failed
   - Move on quickly

5. **Document as you go** (not after)
   - Write docs while doing work
   - Commit frequently
   - Don't batch documentation

---

## ğŸ“ BLOCKERS & ESCALATION

### If Stuck:

1. **Check this plan** - Answer probably here
2. **Check PROJECT_MEMORY.md** - Context might help
3. **Ask in GitHub issue** - Get help from other agent
4. **User decides** - Ultimate decision maker

### Common Blockers:

| Blocker | Solution | Time |
|---------|----------|------|
| "CPU is slow" | Use Colab GPU | Switch now |
| "Missing files" | Check cloud server /tmp/colab_upload/ | 5 min |
| "Unclear next step" | Read this plan | 2 min |
| "Models failing gates" | Retrain with adjusted params | 60 min |
| "Agent confusion" | Check PROJECT_MEMORY.md roles | 2 min |

---

## ğŸ“ˆ PROGRESS TRACKING

### Current Status: Phase 1 - GPU Evaluation

```
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘] 50% Complete

âœ… Data collected (2 years OHLCV)
âœ… Features engineered (31 features)
âœ… Models trained (3 Ã— 50-feature LSTM)
âœ… Colab evaluation prepared
â¸ï¸ Waiting: User to run Colab GPU evaluation
â¬œ Model promotion
â¬œ Production deployment
â¬œ Live trading
```

### Timeline:

| Milestone | Target | Status |
|-----------|--------|--------|
| GPU Evaluation | Today | â¸ï¸ Ready |
| Model Deployment | Today + 4 hours | â¸ï¸ Pending |
| Dry-run Start | Today EOD | â¸ï¸ Pending |
| Live Trading | +5 days | â¸ï¸ Pending |

---

## ğŸ’¡ REMEMBER

**User's Goal**: Big Data â†’ Robust Processing â†’ Real Results

**Our Approach**:
- âœ… Use most powerful tools (Colab GPU)
- âœ… Clear agent roles
- âœ… Fast execution
- âœ… Thorough documentation
- âœ… Quick maintenance

**Never Forget**:
- Speed is critical
- GPU beats CPU
- Document everything
- Clear communication
- Fast iterations

---

**This is the master plan. Follow it. Stay fast. Document everything. Get to production.**

ğŸš€ Let's execute!
